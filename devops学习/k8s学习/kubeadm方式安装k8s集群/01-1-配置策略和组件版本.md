# 使用kubeadm方式部署k8s集群

## 概述

- 本次部署没有使用高可用模式，通过kubeadm将各个组件部署为pod
- 部署使用了5台kvm虚拟机，1台master+etcd,3台node，1台registry(harbor);资源不够的话，也可以1台master，两台node
- kubeadm部署时，默认会从Google的国外网站拉取镜像，访问不到，试验时，将使用阿里和微软的仓库，后期搭建好harbor私有仓库后，可以使用私有仓库进行部署
    - 阿里k8s仓库地址 
      - registry.aliyuncs.com/google_containers
      - registry.cn-hangzhou.aliyuncs.com/google_containers/
      - 参考: <https://cr.console.aliyun.com/cn-hangzhou/instances/images> 需要登录 
    - 微软k8s仓库地址 
      - gcr.azk8s.cn/google_containers   
      - 参考：<http://mirror.azure.cn/help/gcr-proxy-cache.html>
    - 私有仓库
      - 先登录到私有仓库 docker login my_registry_addr
      - 用docker pull 将需要的镜像下载下来，然后docker tag 重新打标签，然后docker push 到私有仓库
      - 参考后续的harbor部署使用

## 配置策略

  -  etcd、kube-apiserver、kube-scheduler、kube-controller-manager ，仅master节点
  -  flannel 集群所有节点，网络组件
  -  docker、kubelet 集群所有节点，二进制安装
  -  kube-proxy 所有节点
  -  集群插件
    - DNS: 使用coredns
    - Dashboard: k8s的web管理页面
    - Metric: metrics-server 指标监控
    - Log: efk: Elasticsearch、Fluend、Kibana 日志收集展示
    - Registry： harbor 私有仓库 

### 环境

  - 五台CentOS 7.6 x64 虚拟机，4c 6g 

## 组件版本

  - docker 通过docker-ce的yum源安装，当前版本19.03.1
  - kubeadm 通过阿里镜像的k8s yum源安装，当前版本1.15.2
  - kubelet 同上
  - etcd、apiserver、scheduler、controller-manager、kube-proxy、coredns 通过kubeadm自动获取；部署时指定k8s版本为1.15.2
  - flanneld 通过github上的yaml文件部署
  - CentOS默认没有启用ipvs，并且CentOS 7.6自带内核3.10据说运行docker有些问题，可以手动升级内核；本次试验使用默认内核，也不安装ipvs
